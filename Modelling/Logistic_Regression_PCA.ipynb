{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with PCA for 7 Zooplanktons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (457454, 53)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tifffile</th>\n",
       "      <th>csvfile</th>\n",
       "      <th>Year</th>\n",
       "      <th>SAM</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>repnum</th>\n",
       "      <th>Loc</th>\n",
       "      <th>SITE</th>\n",
       "      <th>DOY</th>\n",
       "      <th>...</th>\n",
       "      <th>Sigma.Intensity</th>\n",
       "      <th>Roughness</th>\n",
       "      <th>Transparency</th>\n",
       "      <th>Image.File</th>\n",
       "      <th>Particle.ID</th>\n",
       "      <th>Image.Height</th>\n",
       "      <th>Image.Width</th>\n",
       "      <th>Image.X</th>\n",
       "      <th>Image.Y</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04072021_Huron_10_2mm_Rep2_AD_000001.tif</td>\n",
       "      <td>20210407_FISHI_010_2mm_Rep2_VC_data.csv</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>FISHI</td>\n",
       "      <td>STC</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>66.7480</td>\n",
       "      <td>1.8286</td>\n",
       "      <td>0.3171</td>\n",
       "      <td>04072021_Huron_10_2mm_Rep2_AD_000002.tif</td>\n",
       "      <td>99</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>870</td>\n",
       "      <td>0</td>\n",
       "      <td>20210407_FISHI_010_2mm_Rep2_VC_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04072021_Huron_10_2mm_Rep2_AD_000001.tif</td>\n",
       "      <td>20210407_FISHI_010_2mm_Rep2_VC_data.csv</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>FISHI</td>\n",
       "      <td>STC</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>65.6102</td>\n",
       "      <td>1.4038</td>\n",
       "      <td>0.2648</td>\n",
       "      <td>04072021_Huron_10_2mm_Rep2_AD_000005.tif</td>\n",
       "      <td>415</td>\n",
       "      <td>111</td>\n",
       "      <td>99</td>\n",
       "      <td>596</td>\n",
       "      <td>380</td>\n",
       "      <td>20210407_FISHI_010_2mm_Rep2_VC_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04072021_Huron_10_2mm_Rep2_AD_000001.tif</td>\n",
       "      <td>20210407_FISHI_010_2mm_Rep2_VC_data.csv</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>FISHI</td>\n",
       "      <td>STC</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>67.8257</td>\n",
       "      <td>1.2653</td>\n",
       "      <td>0.3878</td>\n",
       "      <td>04072021_Huron_10_2mm_Rep2_AD_000010.tif</td>\n",
       "      <td>905</td>\n",
       "      <td>109</td>\n",
       "      <td>117</td>\n",
       "      <td>901</td>\n",
       "      <td>1105</td>\n",
       "      <td>20210407_FISHI_010_2mm_Rep2_VC_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04072021_Huron_10_2mm_Rep2_AD_000001.tif</td>\n",
       "      <td>20210407_FISHI_010_2mm_Rep2_VC_data.csv</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>FISHI</td>\n",
       "      <td>STC</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>40.7299</td>\n",
       "      <td>1.2742</td>\n",
       "      <td>0.2844</td>\n",
       "      <td>04072021_Huron_10_2mm_Rep2_AD_000019.tif</td>\n",
       "      <td>1649</td>\n",
       "      <td>97</td>\n",
       "      <td>72</td>\n",
       "      <td>1029</td>\n",
       "      <td>247</td>\n",
       "      <td>20210407_FISHI_010_2mm_Rep2_VC_data.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04072021_Huron_10_2mm_Rep2_AD_000001.tif</td>\n",
       "      <td>20210407_FISHI_010_2mm_Rep2_VC_data.csv</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>FISHI</td>\n",
       "      <td>STC</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>61.2308</td>\n",
       "      <td>1.3379</td>\n",
       "      <td>0.2839</td>\n",
       "      <td>04072021_Huron_10_2mm_Rep2_AD_000020.tif</td>\n",
       "      <td>1736</td>\n",
       "      <td>115</td>\n",
       "      <td>93</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>20210407_FISHI_010_2mm_Rep2_VC_data.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   tifffile  \\\n",
       "0  04072021_Huron_10_2mm_Rep2_AD_000001.tif   \n",
       "1  04072021_Huron_10_2mm_Rep2_AD_000001.tif   \n",
       "2  04072021_Huron_10_2mm_Rep2_AD_000001.tif   \n",
       "3  04072021_Huron_10_2mm_Rep2_AD_000001.tif   \n",
       "4  04072021_Huron_10_2mm_Rep2_AD_000001.tif   \n",
       "\n",
       "                                   csvfile  Year  SAM  Month  Day  repnum  \\\n",
       "0  20210407_FISHI_010_2mm_Rep2_VC_data.csv  2021   10      4    7       2   \n",
       "1  20210407_FISHI_010_2mm_Rep2_VC_data.csv  2021   10      4    7       2   \n",
       "2  20210407_FISHI_010_2mm_Rep2_VC_data.csv  2021   10      4    7       2   \n",
       "3  20210407_FISHI_010_2mm_Rep2_VC_data.csv  2021   10      4    7       2   \n",
       "4  20210407_FISHI_010_2mm_Rep2_VC_data.csv  2021   10      4    7       2   \n",
       "\n",
       "     Loc SITE  DOY  ...  Sigma.Intensity  Roughness  Transparency  \\\n",
       "0  FISHI  STC   97  ...          66.7480     1.8286        0.3171   \n",
       "1  FISHI  STC   97  ...          65.6102     1.4038        0.2648   \n",
       "2  FISHI  STC   97  ...          67.8257     1.2653        0.3878   \n",
       "3  FISHI  STC   97  ...          40.7299     1.2742        0.2844   \n",
       "4  FISHI  STC   97  ...          61.2308     1.3379        0.2839   \n",
       "\n",
       "                                 Image.File  Particle.ID  Image.Height  \\\n",
       "0  04072021_Huron_10_2mm_Rep2_AD_000002.tif           99           130   \n",
       "1  04072021_Huron_10_2mm_Rep2_AD_000005.tif          415           111   \n",
       "2  04072021_Huron_10_2mm_Rep2_AD_000010.tif          905           109   \n",
       "3  04072021_Huron_10_2mm_Rep2_AD_000019.tif         1649            97   \n",
       "4  04072021_Huron_10_2mm_Rep2_AD_000020.tif         1736           115   \n",
       "\n",
       "   Image.Width  Image.X  Image.Y                                 Filename  \n",
       "0           95      870        0  20210407_FISHI_010_2mm_Rep2_VC_data.csv  \n",
       "1           99      596      380  20210407_FISHI_010_2mm_Rep2_VC_data.csv  \n",
       "2          117      901     1105  20210407_FISHI_010_2mm_Rep2_VC_data.csv  \n",
       "3           72     1029      247  20210407_FISHI_010_2mm_Rep2_VC_data.csv  \n",
       "4           93      171        0  20210407_FISHI_010_2mm_Rep2_VC_data.csv  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged dataset\n",
    "data_path = \"/Users/willwu/Documents/GitHub/Zooplankton/plankton_data/Merged_Master_Subset_2.csv\"  # Update path if necessary\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display dataset info\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['Class', 'WaterT', 'AvgDepth', 'PRECIP', 'DOY', 'Aspect.Ratio',\n",
      "       'Circularity', 'Diameter..ABD.'],\n",
      "      dtype='object')\n",
      "Missing Values per Column:\n",
      " Class             0\n",
      "WaterT            0\n",
      "AvgDepth          0\n",
      "PRECIP            0\n",
      "DOY               0\n",
      "Aspect.Ratio      0\n",
      "Circularity       0\n",
      "Diameter..ABD.    0\n",
      "dtype: int64\n",
      "Rows with Missing Values:\n",
      " Empty DataFrame\n",
      "Columns: [Class, WaterT, AvgDepth, PRECIP, DOY, Aspect.Ratio, Circularity, Diameter..ABD.]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    \"Class\",          # Target Variable\n",
    "    \"WaterT\",         # Environmental\n",
    "    \"AvgDepth\",\n",
    "    \"PRECIP\",\n",
    "    \"DOY\",\n",
    "    \"Aspect.Ratio\",   # Shape Features\n",
    "    \"Circularity\",\n",
    "    \"Diameter..ABD.\"  # Size Feature (Chosen over Perimeter, Area)\n",
    "]\n",
    "\n",
    "df = df[features]\n",
    "\n",
    "# Display selected columns\n",
    "print(\"Selected Features:\", df.columns)\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(\"Missing Values per Column:\\n\", df.isnull().sum())\n",
    "\n",
    "# Print out the rows with missing values in these columns\n",
    "missing_values = df[df.isnull().any(axis=1)]\n",
    "print(\"Rows with Missing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willwu/Documents/GitHub/Zooplankton/plankton_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Bosmina_1      0.556     0.803     0.657      1445\n",
      "   Calanoid_1      0.814     0.485     0.608     49678\n",
      "   Chironomid      0.096     0.831     0.173       308\n",
      "   Chydoridae      0.002     0.476     0.004        21\n",
      "  Cyclopoid_1      0.725     0.623     0.670     39579\n",
      "      Daphnia      0.009     0.545     0.017       112\n",
      "Herpacticoida      0.019     0.595     0.037       348\n",
      "\n",
      "     accuracy                          0.551     91491\n",
      "    macro avg      0.317     0.623     0.309     91491\n",
      " weighted avg      0.765     0.551     0.631     91491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Feature selection\n",
    "features = [\n",
    "    \"WaterT\",         # Environmental\n",
    "    \"AvgDepth\",\n",
    "    \"PRECIP\",\n",
    "    \"DOY\",\n",
    "    \"Aspect.Ratio\",   # Shape Features\n",
    "    \"Circularity\",\n",
    "    \"Diameter..ABD.\"  # Size Feature\n",
    "]\n",
    "\n",
    "# 1. Split original data\n",
    "X = df[features]\n",
    "y = df[\"Class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2. Apply SMOTE only on training set\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Train the model\n",
    "model = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# 5. Evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with PCA for All Zooplanktons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willwu/Documents/GitHub/Zooplankton/plankton_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8167624795800027\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Bosmina_1      0.786     0.839     0.812      1325\n",
      "      Bubbles      0.939     0.948     0.943       904\n",
      "   Calanoid_1      0.774     0.819     0.796     16025\n",
      "   Chironomid      0.722     0.572     0.639       304\n",
      "   Chydoridae      0.000     0.000     0.000        19\n",
      "   CopepodSpp      0.476     0.222     0.303      1763\n",
      "   CountGT500      0.704     0.241     0.359      2498\n",
      "      Cyclo_2      0.619     0.236     0.342      3335\n",
      "  Cyclopoid_1      0.709     0.896     0.792     17282\n",
      "      Daphnia      0.619     0.160     0.255        81\n",
      "       Floc_1      0.912     0.916     0.914     19695\n",
      "Herpacticoida      0.463     0.259     0.333       293\n",
      "     LargeZ-1      0.940     0.942     0.941     15662\n",
      "        other      0.329     0.069     0.114      1005\n",
      "\n",
      "     accuracy                          0.817     80191\n",
      "    macro avg      0.642     0.509     0.539     80191\n",
      " weighted avg      0.806     0.817     0.799     80191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load data\n",
    "merged_df = pd.read_csv(\"/Users/willwu/Documents/GitHub/Zooplankton/plankton_data/Merged_Master_All_Clean.csv\")\n",
    "\n",
    "# Convert WIND to numeric direction and speed\n",
    "merged_df[\"WIND\"] = merged_df[\"WIND\"].astype(str)\n",
    "wind_split = merged_df[\"WIND\"].str.split(\"-\", expand=True)\n",
    "merged_df[\"wind_direction\"] = pd.to_numeric(wind_split[0], errors=\"coerce\")\n",
    "merged_df[\"wind_speed\"] = pd.to_numeric(wind_split[1], errors=\"coerce\")\n",
    "merged_df.drop(columns=[\"WIND\"], inplace=True)\n",
    "\n",
    "# Feature list\n",
    "features = [\n",
    "    \"Loc\", \"SITE\", \"DOY\", \"gdd2\", \"WaterT\", \"LAT0\", \"LAT1\", \"LON0\", \"LON1\",\n",
    "    \"avgdepth\", \"XANGLE\", \"PRECIP\", \"XWAVEHT\", \"wind_direction\", \"wind_speed\",\n",
    "    \"CLOUD_PC\", \"AvgDepth\", \"Area..ABD.\", \"Aspect.Ratio\", \"Circularity\",\n",
    "    \"Compactness\", \"Convexity\", \"Elongation\", \"Diameter..ABD.\",\n",
    "    \"Diameter..ESD.\", \"Perimeter\", \"Intensity\", \"Sigma.Intensity\",\n",
    "    \"Roughness\", \"Transparency\"\n",
    "]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "merged_df = pd.get_dummies(merged_df, columns=[\"Loc\", \"SITE\"], prefix=[\"Loc\", \"SITE\"])\n",
    "features = [f for f in features if f not in [\"Loc\", \"SITE\"]]  # remove original\n",
    "features += [col for col in merged_df.columns if col.startswith(\"Loc_\") or col.startswith(\"SITE_\")]\n",
    "\n",
    "# Prepare feature matrix and target\n",
    "X = merged_df[features]\n",
    "y = merged_df[\"Class\"]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "logreg.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = logreg.predict(X_test_pca)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willwu/Documents/GitHub/Zooplankton/plankton_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8165629559426868\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Bosmina_1      0.788     0.839     0.813      1325\n",
      "      Bubbles      0.938     0.949     0.943       904\n",
      "   Calanoid_1      0.774     0.818     0.795     16025\n",
      "   Chironomid      0.720     0.576     0.640       304\n",
      "   Chydoridae      0.000     0.000     0.000        19\n",
      "   CopepodSpp      0.478     0.221     0.302      1763\n",
      "   CountGT500      0.704     0.239     0.357      2498\n",
      "      Cyclo_2      0.622     0.234     0.340      3335\n",
      "  Cyclopoid_1      0.708     0.897     0.792     17282\n",
      "      Daphnia      0.619     0.160     0.255        81\n",
      "       Floc_1      0.912     0.916     0.914     19695\n",
      "Herpacticoida      0.475     0.263     0.338       293\n",
      "     LargeZ-1      0.940     0.942     0.941     15662\n",
      "        other      0.336     0.071     0.117      1005\n",
      "\n",
      "     accuracy                          0.817     80191\n",
      "    macro avg      0.644     0.509     0.539     80191\n",
      " weighted avg      0.806     0.817     0.799     80191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load data\n",
    "merged_df = pd.read_csv(\"/Users/willwu/Documents/GitHub/Zooplankton/plankton_data/Merged_Master_All_Clean.csv\")\n",
    "\n",
    "# Convert WIND to numeric direction and speed\n",
    "merged_df[\"WIND\"] = merged_df[\"WIND\"].astype(str)\n",
    "wind_split = merged_df[\"WIND\"].str.split(\"-\", expand=True)\n",
    "merged_df[\"wind_direction\"] = pd.to_numeric(wind_split[0], errors=\"coerce\")\n",
    "merged_df[\"wind_speed\"] = pd.to_numeric(wind_split[1], errors=\"coerce\")\n",
    "merged_df.drop(columns=[\"WIND\"], inplace=True)\n",
    "\n",
    "# Feature list\n",
    "features = [\n",
    "    \"Loc\", \"SITE\", \"DOY\", \"gdd2\", \"WaterT\", \"LAT0\", \"LAT1\", \"LON0\", \"LON1\",\n",
    "    \"avgdepth\", \"XANGLE\", \"PRECIP\", \"XWAVEHT\", \"wind_direction\", \"wind_speed\",\n",
    "    \"CLOUD_PC\", \"AvgDepth\", \"Area..ABD.\", \"Aspect.Ratio\", \"Circularity\",\n",
    "    \"Compactness\", \"Convexity\", \"Elongation\", \"Diameter..ABD.\",\n",
    "    \"Diameter..ESD.\", \"Perimeter\", \"Intensity\", \"Sigma.Intensity\",\n",
    "    \"Roughness\", \"Transparency\"\n",
    "]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "merged_df = pd.get_dummies(merged_df, columns=[\"Loc\", \"SITE\"], prefix=[\"Loc\", \"SITE\"])\n",
    "features = [f for f in features if f not in [\"Loc\", \"SITE\"]]  # remove original\n",
    "features += [col for col in merged_df.columns if col.startswith(\"Loc_\") or col.startswith(\"SITE_\")]\n",
    "\n",
    "# Prepare feature matrix and target\n",
    "X = merged_df[features]\n",
    "y = merged_df[\"Class\"]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train Logistic Regression model (no PCA)\n",
    "logreg = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plankton_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
